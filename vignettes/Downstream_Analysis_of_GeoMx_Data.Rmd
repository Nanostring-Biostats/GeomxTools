---
title: "Analyzing GeoMx-NGS RNA Data with GeomxTools"
author: "David Henderson, Nicole Ortogero, Jason Reeves, Prajan Divaker, Zhi Yang, Rona Vitancol, Maddy Griswold"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    self_contained: false
    fig_width: 5
    fig_height: 4.5
    mainfont: Arial
    fontfamily: Arial
vignette: >
  %\VignetteIndexEntry{Analyzing GeoMx NGS Data with GeomxTools}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 5,
  fig.height = 4.5,
  dpi=200
)
```

## Introduction

The GeoMx Digital Spatial Profiler (DSP) is platform for capturing protein or gene expression in a spatially resolved manner [Merritt et al., 2020](https://pubmed.ncbi.nlm.nih.gov/32393914/). This vignette walks through analysis of data collected by GeoMx starting from raw count files through downstream biological analysis and interpretation.

GeoMx profiles expression by staining and processing standard histological slides, including fixed-frozen (FF) or formalin-fixed paraffin-embedded (FFPE) tissue sections. Tissue sections are stained with barcoded in-situ hybridization probes that bind to mRNA transcripts or oligo-labeled antibodies which bind to epitopes throughout the tissue. The slide is visualized using up to 4 immunoflorescent (IF) markers which can be IF-labeled antibodies or RNA Scope ISH probes. The user then selects regions of the interest (ROI) based on tissue morphology; if desired, each ROI can be further sub-divided into segments which will be sequentially profiled and are referred to as areas of illumination (AOI). The instrument then collects expression barcodes for each AOI individually, which are sequenced and processed. The final result are expression count files which can contain >18,000 quantified genes for every respective AOI profiled.

### Motivation & Scope

The intent of this vignette is to enable an analyst to work with GeoMx data and understand how workflow of a standard data analysis. This vignette will cover how to:
* Read in GeoMx count files and metadata (DCC, PKC and annotation file)
* Perform QC and normalization to prepare the data for analysis
* Perform downstream analysis and visualize the results including:
  + Dimension reduction with UMAP or t-SNE
  + Differential expression analysis with mixed effect models
  + Generate a heatmap of expression results
  + Pathway analysis based on GSEA 
  + Cell deconvolution 

## Install and load R Packages/libraries 

Let's install and load `GeomxTools` package and other required packages. We are installing from the `dev` branch of the `Geomxtools` package, but in future releases we will demonstrate how to load the code directly from [Bioconductor](https://www.bioconductor.org/packages/release/bioc/html/GeomxTools.html).

```{r libs, message=FALSE, warning=FALSE }
# If you have not done so, install devtools to install needed R packages

install.packages("devtools")
devtools::install_github("Nanostring-Biostats/NanoStringNCTools")
devtools::install_github("Nanostring-Biostats/GeomxTools", ref = "dev")

library(NanoStringNCTools)
library(GeomxTools)
library(EnvStats)
library(ggiraph)
```


### Dataset Introduction

For this demo analysis, we will use a kidney dataset profiled with human whole transcriptome atlas (WTA).

Seven tissue slides were analyzed, 4 diabetic kidney disease (DKD) and 3 healthy kidney. Regions of Interest (ROI) focused on two different kidney structures: tubules or glomeruli. Individual glomeruli were identified by a pathologist as either behaving relatively healthy or diseased regardless on if the tissue was DKD or healthy. One glomerulus ROI contains the entirety of a glomerulus. Tubule ROIs were segmented into distal (PanCK+) and proximal (PanCK-) tubule areas of interest (AOI). While both distal and proximal tubules are called tubules, they perform very different functions in the kidney. 

## Loading Data: DCC files, PKC files and annotation file

Download the demo data here:
[http://nanostring-public-share.s3-website-us-west-2.amazonaws.com/GeoScriptHub/Kidney_Dataset_for_GeomxTools.zip](http://nanostring-public-share.s3-website-us-west-2.amazonaws.com/GeoScriptHub/Kidney_Dataset_for_GeomxTools.zip)

Within the zip file you will find the minimal components necessary for analysis. These three data components are DCCs, PKCs, and the annotation file:
* DCCs contain the expression count data
* PKCs contain information about how each probe is associated with a given target gene or portein and any additional panel metadata
* Annotation file specifies useful tissue/ROI/AOI information, including the type of ROI selected, the number of nuclei within an AOI, and other characteristics of the samples.



```{r quickstart, message=FALSE, warning=FALSE}

# Unzip and place the downloaded Kidney Dataset files
# The downloaded dataset contains three folders each containing the respective metadata. 
# We copy the folder path for the downloaded dataset folder titled, 'Kidney_Dataset", as the datadir below and change the 'slash' orientation from 
# "/" instead of "\"

datadir <- file.path( "C:/Users/MyPC/Downloads/Kidney_Dataset_for_GeomxTools/Kidney_Dataset")

DCCFiles <- dir(file.path(datadir, "dccs"), pattern=".dcc$", full.names=TRUE, recursive=TRUE)
PKCFiles <- dir(file.path(datadir, "pkcs"), pattern=".pkc$", full.names=TRUE, recursive=TRUE)
SampleAnnotationFile <- dir(file.path(datadir, "annotation"), pattern=".xlsx$", full.names=TRUE, recursive=TRUE)

demoData <-
  readNanoStringGeoMxSet(dccFiles = DCCFiles,   # !! Prajan/Rona - suppress warnings should be an option in readNanoStringGeoMxSet
                         pkcFiles = PKCFiles,
                         phenoDataFile = SampleAnnotationFile,
                         phenoDataSheet = "Template",
                         phenoDataDccColName = "Sample_ID",
                         protocolDataColNames = c("aoi", 
                                                  "roi"),
                         experimentDataColNames = c("panel",
                                                    "instrument_type"))

# Shift counts to one to mimic how DSPDA handles zero counts
demoData <- shiftCountsOne(demoData, elt="exprs", useDALogic=TRUE) 
```

## Quality Control Assessment

### Segment QC 

First, we will check sequencing quality and adequate tissue sampling for every segment / AOI. For each segment there are several steps along the way to generating a count matrix, each with it's own quality metric associated and recommended threshold. FASTQ files are generated and converted to DCC files, but before we aggregate DCC files we need to check the sequencing quality within the FASTQ files. We will determine if the samples pass QC based on the number of reads per sample, the percent or reads trimmed and aligned, as well as the sequencing saturation (1 - % unique reads). We will also confirm the number of nuclei & area associated with each segment. At the end of this section we will summarize the breakdown of flags observed, and total number of segments/AOIs that have been flagged for QC failures.

```{r setqcflagupdated,  eval = TRUE}
demoData <- setSegmentQCFlags(demoData, 
                              qcCutoffs = list(minSegmentReads = 1000, # Minimum number of reads
                                               percentAligned = 75,    # Minimum % of reads aligned to known targets
                                               percentSaturation = 50, # Minimum sequencing saturation
                                               minNegativeCount = 5,   # Minimum negative control counts
                                               maxNTCCount = 150,      # Maximum counts observed in NTC well
                                               minNuclei = 15000,      # <- this is swapped?
                                               minArea = 20))          # <- this is swapped?
summary(sData(demoData)[["QCFlags"]])

prData <- protocolData(demoData)
QCResults <- prData[["QCFlags"]]
QCResults <- as.data.frame(QCResults)

# Append relevant variables to the the QC results dataframe. 
QCResults <- cbind(QCResults, sData(demoData)[c( "Raw", "Trimmed", "Trimmed (%)",
                                                 "DeduplicatedReads", "Saturated (%)",
                                                 "Aligned", "Aligned (%)", "Stitched",
                                                 "Stitched (%)", "NTC", "NegGeoMean", 
                                                 "area", "nuclei")])

# Flag sample as PASS or WARNING if sample has a QC flag
QCResults$QCStatus <- apply(prData[["QCFlags"]], 1L, function(x) {
        y <- sum(x) == 0L
        y <- ifelse(y, "PASS", "WARNING")
        return(y)
    })

QCResults <- cbind(QCResults, sData(demoData)[c("aoi", "roi", "slide name")])

## produce QC Table here
flag_columns <- c(colnames(QCResults)[grepl('Low', colnames(QCResults))],
                  colnames(QCResults)[grepl('High', colnames(QCResults))])
QC_Summary <- data.frame(Pass = colSums(!QCResults[, flag_columns]),
                         Warning = colSums(QCResults[, flag_columns]))
QC_Summary['Total Flags', ] <- c(sum(QCResults[, 'QCStatus'] == 'PASS'),
                                sum(QCResults[, 'QCStatus'] == 'WARNING'))
print(QC_Summary) # Format table later

```

To view the distribution of these statistics we will generate a few graphs with a quick function to draw histograms of our data using `ggplot2`.

``` {r qcflaghistograms,  eval = TRUE}

# Graphical summaries of QC statistics
QC_histogram <- function(assay_data = NULL,
                         annotation = NULL,
                         fill_by = NULL,
                         thr = NULL,
                         xlims = NULL) {
  if(is.null(xlims)) {
    xlims <- range(assay_data[, annotation])
  }
  plt <- ggplot(assay_data,
                aes_string(x = paste0('unlist(`', annotation, '`)'),
                           fill = fill_by)) +
    geom_histogram(bins = 50) +
    geom_vline(xintercept = thr, lty = 'dashed', color = 'orange2') +
    theme_bw() +
    facet_wrap(as.formula(paste('~', fill_by)), nrow = 8) +
    xlim(xlims) +
    labs(x = annotation, y = 'AOIs, #', title = annotation)
  suppressWarnings(print(plt))
}

## Troubleshoot error:
##   Warning message:
##   Removed 8 rows containing missing values (geom_bar).

QC_histogram(sData(demoData), 'Aligned (%)', 'region', 80, c(0,100))
QC_histogram(sData(demoData), 'Stitched (%)', 'region', 80, c(0,100))
QC_histogram(sData(demoData), 'Trimmed (%)', 'region', 80, c(0,100))
QC_histogram(sData(demoData), 'Saturated (%)', 'region', 80, c(0,100))
QC_histogram(sData(demoData), 'NegGeoMean', 'region', 5)
QC_histogram(sData(demoData), 'area', 'region', 15000)
QC_histogram(sData(demoData), 'nuclei', 'region', 20)

```

###  Exclude samples that did not pass Sequencing QC

```{r removeQCSampleProbe,  eval = TRUE}
QCResultsIndex <- which(apply(protocolData(demoData)[["QCFlags"]], 
                              1L , function(x) sum(x) == 0L))
QCPassed <- demoData[, QCResultsIndex]

# QC Passed is your pruned dataset without the Sequencing QC warning AOIs
# Setting demoData to contain only those that passed AOI QC
demoData <- QCPassed
dim(demoData) 

```

### Biological Probe QC 

In some GeoMx assays we rely on multiple probes per target to represent expression of a given gene. Across all NGS read-out assays, there are multiple probes representing our negative controls, which should not bind to any sequence in the human genome. Before we summarize our data into a count matrix, we will remove probes for which we observe expression that appears spurious. This process is called global and local outlier removal, which is performed on either a per gene (global) or per gene per AOI (local) basis, filtering out outlier probes that do no behave consistently. This process is only performed for genes where there are multiple ISH probes related to that target, so for our example data it will only be performed on the negative control probes. This process will always leave at least one probe representing the gene or biological target class in the dataset after the process.

#### Set Biological Probe QC flags using default settings from DSPDA

```{r setbioprobeqcflag,  eval = TRUE}
# Generally keep the qcCutoffs parameters unchanged. Set removeLocalOutliers to 
# FALSE if you do not want to remove local outliers
demoData <- setBioProbeQCFlags(demoData, 
                               qcCutoffs=list(minProbeRatio=0.1,
                                              percentFailGrubbs=20), 
                               removeLocalOutliers=TRUE)

ProbeQCResults <- fData(demoData)[["QCFlags"]]

# Define QC table for Probe QC
data.frame(Passed = sum(rowSums(ProbeQCResults[, -1]) == 0),
           Global = sum(ProbeQCResults$GlobalGrubbsOutlier),
           Local = sum(rowSums(ProbeQCResults[, -2:-1])>0))

```

#### Exclude Outlier Probes

```{r}  
#Subset object to exclude all that did not pass Global Bioprobe QC and Outlier Ratio QC
ProbeQCPassed <- subset(demoData, 
                     fData(demoData)[["QCFlags"]][,c("LowProbeRatio")]== FALSE &
                       fData(demoData)[["QCFlags"]][,c("GlobalGrubbsOutlier")]== FALSE)
dim(ProbeQCPassed)
demoData <- ProbeQCPassed 
```

### Calculate Limit of Quantification

In addition to outlier detection, we must now determine the limit of quantification. This is calculated based on the distribution of negative control probes, and is intended to represent the quantifiable limit of gene expression per segment, under which gene expression is no longer reliable. Please note that this process is more stable in larger segments, and AOIs with low area, and subsequently low negative control probe distributions, the LOQ may not be accurately reflective of true signal detection rates. The formula for calculating the LOQ in the _i_^th^ segment/AOI is: $$LOQ_{i} = geomean(NegProbe_{i}) * geoSD(NegProbe_{i})^{n}$$

In the example below we use 2 geometric standard deviations (n = 2) above the geometric mean as the cutoff, which is recommended for most use cases. We also recommend that a minimum LOQ of 2 be used even if the LOQ calculated to be below this threshold.

``` {r, eval = TRUE}
# Create a function to define and calculate the LOQ:
calc_LOQ <- function(object = NULL,
                     cutoff = 2,
                     minLOQ = 2) {
  negativeObject <- negativeControlSubset(object)
  esApply(negativeObject, MARGIN=2, FUN=function(x) {
    pmax(ngeoMean(x) * ngeoSD(x) ^ cutoff, minLOQ)})
}

pData(demoData)$LOQ <- calc_LOQ(demoData)

```

#### Create Gene-level Count Data

After calculating the LOQ we will generate a target count matrix. This will summarize all multi-probe targets into a single value represented as the geometric mean of those probes.

```{r, eval = TRUE}
# Check how many unique targets the object has
length(unique(featureData(demoData)[["TargetName"]]))

# collapse to targets
target_demoData <- aggregateCounts(demoData)
dim(target_demoData)
exprs(target_demoData)[1:5, 1:5]

# I believe the rest of the code in this block is un-used except for demonstration purposes???
# 
# TargetCountMatrix <- exprs(target_demoData)
# 
# # Add annotations (scan name, roi, segment, aoi) 
# # Access Count matrix With Probe information (AOIs are rows and targets as columns)
# TargetCountMatrix <- (munge(target_demoData, mapping = ~ exprs + `roi` + 
#                               `slide name` + `segment` + `aoi` ))
# # convert the results above to wide format
# TargetCountMatrix <- tidyr::spread(TargetCountMatrix, FeatureName, exprs)
# dim(TargetCountMatrix)
# TargetCountMatrix[1:4, 1:10]

```

### Segment/AOI Filtering

We recommend removing poor performing AOIs before further analysis as they may unduly influence interpretation downstream. Please note that if there are rare segment classes that are only represented by a few AOIs, that you may want to skip this section, but that interpretation of these segments should primarily be qualitative, not quantitative to prevent biased interpretation of the data.

{Include section on Segment filtering - Q90 distribution?}

// need input from team here on what to show or if we should skip this section

### Gene Filtering 

After filtering segments with poor detection, we recommend removing genes which were poorly detected. This helps improve performance during downstream statistical tests, decreases multiple testing penalties, and may prevent interpreting stochastic expression of genes near the LOQ as biological signal.

First we will determine the number of genes detected at various cutoffs across our dataset. For each gene will will determine how many segments have expression > LOQ, and plot this information to help select a cutpoint for minimal detection. We will also show you how to determine for genes of interest how many AOIs it's detected in.

``` {r, eval = TRUE}

pData(target_demoData)$LOQ <- pData(demoData)$LOQ

LOQ_Mat <- esApply(target_demoData, MARGIN=2, FUN=function(x) {
  x > LOQ})
pData(target_demoData)$GenesDetected <- colSums(LOQ_Mat, na.rm = TRUE)
fData(target_demoData)$DetectedSegments <- rowSums(LOQ_Mat, na.rm = TRUE)
fData(target_demoData)$DetectionRate <- fData(target_demoData)$DetectedSegments / nrow(pData(target_demoData))

# Gene of interest detection table:
goi <- c('PDCD1','CD274','IFNG','CD8A','CD68','EPCAM','KRT18','NPHS1','CALB1','CLDN8')
data.frame(Gene = goi,
           Detection = fData(target_demoData)[goi, 'DetectedSegments'],
           Rate = round(fData(target_demoData)[goi, 'DetectionRate'] * 100, 1))

# Plot detection rate:
plot_detect <- data.frame(Freq = c(1, 5, 10, 20, 30, 50))
plot_detect$Number <-
  unlist(lapply(c(0.01, 0.05, 0.1, 0.2, 0.3, 0.5),
                function(x) {sum(fData(target_demoData)$DetectionRate >= x)}))
plot_detect$Rate <- plot_detect$Number / nrow(fData(target_demoData))
rownames(plot_detect) <- plot_detect$Freq

ggplot(plot_detect, aes(x = as.factor(Freq), y = Rate, fill = Rate)) +
    geom_bar(stat = 'identity') +
    geom_text(aes(label = formatC(Number, format = 'd', big.mark = ',')),
              vjust=1.6, color = 'black', size = 5) +
    scale_fill_gradient2(low = 'orange2', mid = 'lightblue',
                         high = 'dodgerblue3', midpoint = 0.65,
                         limits = c(0,1),
                         labels = scales::percent) +
    theme_bw(base_size = 15) +
    scale_y_continuous(labels = scales::percent, limits = c(0,1),
                       expand = expansion(mult = c(0, 0))) +
    labs(x = '% of Segments',
         y = 'Genes Detected, % of Panel > LOQ')

```

As we have confirmed that all target genes of interest are detected at > 5% of AOIs, we will out genes detected in < 5% of segments. If a target gene was detected in < 5% of AOIs, it could be manually saved or a lower threshold could be selected.

``` {r, eval = TRUE}

# Subset to target genes detected in at least 5% of the samples.
target_demoData <- target_demoData[fData(target_demoData)$DetectionRate > 0.05, ]

```

## Normalization

We will now normalize the GeoMx data for downstream visualizations and differential expression. Two common methods for normalization are i) Quartile 3 or ii) background normalization.

Both of these normalization methods rely on the distribution of the data to estimate a normalization factor to roughly bring the data distributions together. More advanced methods for normalization and modelings are under active development, however, for most projects these methods are sufficient for understanding differences between biological classes of segments and samples. Additionally other packages such as `limma` and `voom` may also be appropriate in some cases.

Before we choose a normalization factor to use, we will explore the relationship between the upper quartile (Q3) of the counts in each segment with the geometric mean of the negative control probes in the data. We'd ideally like there to be separation between these two values before normalizing to one of them. If you do not see sufficient seperation between these values, you may need to be more aggressive with filtering out low-expressing genes.

For additional guidance, please refer to our [Data Analysis & Normalization White Paper for DSP-NGS Assays](whitepaper url)

``` {r, Review normalization factors, eval = TRUE}

# Graph Q3 value vs negGeoMean of Negatives
ann_of_interest <- 'region'
neg_probe <- rownames(exprs(target_demoData))[grepl('Neg', rownames(target_demoData@assayData$exprs))]
Stat_data <- data.frame(row.names = colnames(exprs(target_demoData)),
                        AOI = colnames(exprs(target_demoData)),
                        Annotation = pData(target_demoData)[, ann_of_interest],
                        Q3 = unlist(apply(exprs(target_demoData), 2, quantile, 0.75, na.rm = TRUE)),
                        NegProbe = exprs(target_demoData)[neg_probe, ])
Stat_data_m <- melt(Stat_data, measure.vars = c('Q3','NegProbe'),
                    variable.name = 'Statistic', value.name = 'Value')

ggplot(Stat_data_m, aes(x = Value, fill = Statistic)) +
  geom_histogram(bins = 40) + 
  theme_bw() +
  facet_wrap(~Annotation, nrow = 5) +
  scale_x_continuous(trans = 'log2') +
  labs(x = 'Counts', y = 'AOIs, #')

ggplot(Stat_data, aes(x = NegProbe, y = Q3, color = Annotation)) +
  geom_abline(intercept = 0, slope = 1, lty = 'dashed', color = 'darkgray') +
  geom_point() + 
  theme_bw() +
  scale_x_continuous(trans = 'log2') +
  scale_y_continuous(trans = 'log2') +
  labs(x = 'Negative Probe GeoMean, Counts', y = 'Upper Quartile Value, Counts')

ggplot(Stat_data, aes(x = NegProbe, y = Q3/NegProbe, color = Annotation)) +
  geom_hline(yintercept = 1, lty = 'dashed', color = 'darkgray') +
  geom_point() + 
  theme_bw() +
  scale_x_continuous(trans = 'log2') +
  scale_y_continuous(trans = 'log2') +
  labs(x = 'Negative Probe GeoMean, Counts', y = 'Upper Quartile/NegProbe Value, Counts')

rm(list = c('Stat_data','Stat_data_m'))

```

```{r normalizeObject, eval = TRUE}
# Q3 norm (75th percentile) for WTA/CTA  with or without custom spike-ins
target_demoData <- normalize(target_demoData , data_type = "RNA", norm_method = "quant", 
                             desiredQuantile = .75, toElt = "q_norm")

# Background normalization for WTA/CTA without custom spike-in
target_demoData <- normalize(target_demoData , data_type = "RNA", norm_method = "neg", 
                             fromElt = "exprs",  toElt = "neg_norm")

# Note that Negative normalization is not acceptable for custom spike-ins in this R pipeline {is this true?}
assayDataElement(target_demoData , elt = "q_norm")[1:5, 1:5]
assayDataElement(target_demoData , elt = "neg_norm")[1:5, 1:5]
NormCountMatrix <- assayDataElement(target_demoData, "q_norm")

# Add annotations (scan name, roi, segment, aoi) 
# Access Count matrix With Probe information (AOIs are rows and targets as columns)
NormCountMatrix <- munge(target_demoData, mapping = ~q_norm + `roi` + 
                           `slide name` + `segment` + `aoi` )
# convert the results above to wide format
NormCountMatrix <- tidyr::spread(NormCountMatrix, FeatureName, q_norm)
dim(NormCountMatrix)
NormCountMatrix[1:4, 1:10]

# visualize the first 10 segments with each normalization method
boxplot(exprs(target_demoData)[,1:10], col = '#9EDAE5', main = 'Raw Counts',
        log = 'y', names = 1:10, xlab = 'Segment', ylab = 'Counts, Raw')
boxplot(assayDataElement(target_demoData[,1:10], elt = 'q_norm'), col = '#2CA02C', main = 'Q3 Norm Counts',
        log = 'y', names = 1:10, xlab = 'Segment', ylab = 'Counts, Q3 Normalized')
boxplot(assayDataElement(target_demoData[,1:10], elt = 'neg_norm'), col = '#FF7F0E', main = 'Neg Norm Counts',
        log = 'y', names = 1:10, xlab = 'Segment', ylab = 'Counts, Neg. Normalized')

```

## Downstream Analysis

### Dimension Reduction: UMAP & t-SNE

One common approach to understanding the data after normalization is to plot the data in a reduced dimensionality space. Two common methods for this are UMAP and tSNE projections, which are non-orthogonally constrained projections which can cluster samples based on overall gene expression rates. 

``` {r umap, eval = TRUE}
# !!!!things to update: q3 accession - something is wrong above and q3 is failing

library(umap)
# update defaults for umap to contain a stable random_state (seed)
custom_umap <- umap.defaults
custom_umap$random_state <- 42

# run UMAP
umap_out <- umap(t(na.omit(log2(assayDataElement(target_demoData , elt = "q_norm")))),  
                 config = custom_umap)
pData(target_demoData)$UMAP1 <- umap_out$layout[,1]
pData(target_demoData)$UMAP2 <- umap_out$layout[,2]

ggplot(pData(target_demoData),
       aes(x = UMAP1, y = UMAP2, color = region, shape = pathology)) +
  geom_point(size = 3) +
  theme_bw()

```

``` {r tsne, eval = TRUE}

library(Rtsne)
# run UMAP
tsne_out <- Rtsne(t(na.omit(log2(assayDataElement(target_demoData , elt = "q_norm")))), perplexity = 15)
pData(target_demoData)$tSNE1 <- tsne_out$Y[,1]
pData(target_demoData)$tSNE2 <- tsne_out$Y[,2]

ggplot(pData(target_demoData),
       aes(x = tSNE1, y = tSNE2, color = region, shape = pathology)) +
  geom_point(size = 3) +
  theme_bw()

```

### Differential Expression

A common method for understanding distinctions between sets of segments or patients is to perform differential expression analysis. While more advanced methods for modeling the underlying count distribution are being actively developed, a simple approach to performing differential expression testing is to use a mixed-effect regression to estimate differences in mean expression between groups of ROIs, while accounting for the fact that the groups may have slide-specific effects using a random slope or random slope & intercept based on slide or sample. Essentially, the random slope or intercept is used to control for slide-specific effects, while modeling distinctions in the test of interest. Below we use the package `lme4` to model the data and `lmerTest` to estimate the significance of interactions. For more information about mixed effect modes please see [the original lme4 documentation](link to LME4).

``` {r DE}
library(lme4)
library(lmerTest)

##NOTE: monocole includes a multi-core application of esApply. writing qNorm to
##the primary data slot for exprs might allow this to be used instead of
##assayDataApply which in theory would be able to speed this up some.
##   https://rdrr.io/bioc/monocle/man/mcesApply.html

# DE results are just returned as a table here, but could also be stored in fData

# Use case:
# Glomeruli vs Tubules - mixed slope + intercept because the test is performed
#     comparing paired ROIs within a slide 

lmm <- function(y) {
  coef(summary(lmer(log2(y) ~ region + (1 + `slide name`| `slide name`))))[2, c(1,5)]
}
results <- t(suppressMessages(assayDataApply(target_demoData,
                                             elt = "q_norm", MARGIN = 1, lmm)))
results <- as.data.frame(results)
results$FDR <- p.adjust(results$`Pr(>|t|)`, method = 'fdr')
head(results)

# Categorize Results based on P-value & FDR for plotting
results$Color <- 'NS or FC < 0.5'
results$Color[results$P < 0.05] <- 'P < 0.05'
results$Color[results$FDR < 0.05] <- 'FDR < 0.05'
results$Color[results$FDR < 0.001] <- 'FDR < 0.001'
results$Color[abs(results$Estimate) < 0.5] <- 'NS or FC < 0.5'
results$Color <- factor(results$Color, levels = c('NS or FC < 0.5', 'P < 0.05', 'FDR < 0.05', 'FDR < 0.001'))
results$Gene <- rownames(results)

# Graph results
plt <- ggplot(results,
              aes(x = Estimate, y = -log10(`Pr(>|t|)`),
                  color = Color, label = Gene)) +
  geom_vline(xintercept = c(0.5, -0.5), lty = 'dashed') +
  geom_hline(yintercept = -log10(0.05), lty = 'dashed') +
  geom_point() +
  labs(x = 'Enriched in Glomeruli <- log2(FC) -> Enriched in Tubules',
       y = 'Significance, -log10(P)',
       color = 'Significance') +
  scale_color_manual(values = c(`FDR < 0.001` = 'dodgerblue',
                                `FDR < 0.05` = 'lightblue',
                                `P < 0.05` = 'orange2',
                                `NS or FC < 0.5` = 'gray')) +
  scale_y_continuous(expand = expansion(mult = c(0,0.05))) +
  geom_text_repel(data = subset(results, `Pr(>|t|)` < 1e-13),
                  size = 3.5, point.padding = 0.15, color = 'black',
                  min.segment.length = .1, box.padding = .2, lwd = 2) +
  theme_bw()

print(plt)

# # Test 2: [[[THIS SECTION ISN"T FINISHED YET]]]
# # Glom - disease vs normal - subset & then DE mixed slope only, as this is
# #     a test of groups of slides
# 
# # within structure disease vs normal
# lmm <- function(y) {
#   coef(summary(lmer(log2(y) ~ class + (1 | `slide name`))))[2, c(1,5)]
# }
# 
# results_t2 <- c()
# for(structure in unique(pData(target_demoData)$region)) {
#   tmp_res <- t(assayDataApply(target_demoData[1:100, target_demoData$region == structure],
#                               elt = "neg_norm", MARGIN = 1, lmm))
#   tmp_res <- as.data.frame(tmp_res)
#   tmp_res$FDR <- p.adjust(tmp_res$`Pr(>|t|)`, method = 'fdr')
#   tmp_res$Structure <- structure
#   results_t2 <- rbind(tmp_res, results_t2)
# }
# 

```

### Visualizing differentially expressed genes with boxplots and heatmaps

[TEXT HERE]

``` {r boxplot}
# show expression for a single target: NPHS1
ggplot(pData(target_demoData),
       aes(x = region, fill = region,
           y = assayDataElement(target_demoData['NPHS1', ], elt = 'neg_norm'))) +
  geom_boxplot() +
  labs(y = 'NPHS1') +
  scale_y_continuous(trans = 'log2') +
  theme_bw()

```

[TEXT HERE]

``` {r heatmap}
library(pheatmap)

# select top significant genes based on significance & filter any with NA's
GOI <- subset(results, `Pr(>|t|)` < 1e-10)$Gene
any_NA <- rowSums(is.na(assayDataElement(target_demoData[GOI, ], elt = 'q_norm')))
GOI <- GOI[any_NA == 0]
pheatmap(assayDataElement(target_demoData[GOI, ], elt = 'q_norm'),
         scale = 'row', 
         show_rownames = FALSE,
         show_colnames = FALSE,
         border_color = NA,
         clustering_distance_rows = 'correlation',
         clustering_distance_cols = 'correlation',
         clustering_method = 'average',
         breaks = seq(-3, 3, 0.05),
         color = colorRampPalette(c('purple3','black','yellow2'))(120),
         annotation_col = pData(target_demoData)[, c('region','class')])

# The GeomxTools package also includes heatmap functionality in the graph
# autoplot as a simple additional method for graphing your data
autoplot(target_demoData[GOI, ], type = 'heatmap-genes',
         elt = 'q_norm', heatmapGroup = c('region','class'))

```

### Pathway analysis & Cell Decon [Stretch]

``` {r }