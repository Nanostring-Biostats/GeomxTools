---
title: "Analyzing GeoMx-NGS Data with GeomxTools"
author: "David Henderson, Nicole Ortogero, Jason Reeves, Prajan Divaker, Zhi Yang, Rona Vitancol, Maddy Griswold"
date: "`r Sys.Date()`"
output: 
  prettydoc::html_pretty:
    theme: cayman
    toc: true
    self_contained: false
    fig_width: 5
    fig_height: 4.5
    mainfont: Arial
    fontfamily: Arial
vignette: >
  %\VignetteIndexEntry{Analyzing GeoMx NGS Data with GeomxTools}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: inline
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 5,
  fig.height = 4.5,
  dpi=200
)
```

## Introduction

The GeoMx Digital Spatial Profiler (DSP) is platform for capturing protein or gene expression in a spatially resolved manner [Merritt et al., 2020](https://pubmed.ncbi.nlm.nih.gov/32393914/). This vignette walks through analysis of data collected by GeoMx starting from raw count files through downstream biological analysis and interpretation.

GeoMx profiles expression by staining and processing standard histological slides, including fixed-frozen (FF) or formalin-fixed paraffin-embedded (FFPE) tissue sections. Tissue sections are stained with barcoded in-situ hybridization probes that bind to mRNA transcripts or oligo-labeled antibodies which bind to epitopes throughout the tissue. The slide is visualized using up to 4 immunoflorescent (IF) markers which can be IF-labeled antibodies or RNA Scope ISH probes. The user then selects regions of the interest (ROI) based on tissue morphology; if desired, each ROI can be further sub-divided into segments which will be sequentially profiled and are referred to as areas of illumination (AOI). The instrument then collects expression barcodes for each AOI individually, which are sequenced and processed. The final result are expression count files which can contain >18,000 quantified genes for every respective AOI profiled.

### Motivation & Scope

The intent of this vignette is to enable an analyst to work with GeoMx data and understand how workflow of a standard data analysis. This vignette will cover how to:

* Read in GeoMx count files and metadata (DCC, PKC and annotation file)
* Perform QC and normalization to prepare the data for analysis
* Perform downstream analysis and visualize the results including:
    + Dimension reduction with UMAP or t-SNE
    + Differential expression analysis with mixed effect models
    + Generate a heatmap of expression results
    + Pathway analysis based on GSEA 
    + Cell deconvolution 

## Install and load R Packages/libraries 

Let's install and load `GeomxTools` package and other required packages. We are installing from the `dev` branch of the `Geomxtools` package, but in future releases we will demonstrate how to load the code directly from [Bioconductor](https://www.bioconductor.org/packages/release/bioc/html/GeomxTools.html).

```{r installPackages, message = FALSE, warning = FALSE, eval = FALSE}
# If you have not done so, install devtools to install needed R packages

install.packages("devtools")
devtools::install_github("Nanostring-Biostats/NanoStringNCTools")
devtools::install_github("Nanostring-Biostats/GeomxTools", ref = "dev")

```

```{r libs, message = FALSE, warning = FALSE, eval = TRUE}
library(NanoStringNCTools)
library(GeomxTools)
library(EnvStats)
library(ggrepel)   # for ggplot graphs
library(reshape2)  # for melt
library(umap)      # for umap
library(Rtsne)     # for Rtsne
library(lme4)      # for lmer
library(lmerTest)  # for p-values for lmer
library(pheatmap)  # for pheatmap
library(knitr)     # for kable
library(cowplot)   # for plot_grid

```


### Dataset Introduction

For this demo analysis, we will use a kidney dataset profiled with human whole transcriptome atlas (WTA).

Seven tissue slides were analyzed, 4 diabetic kidney disease (DKD) and 3 healthy kidney. Regions of Interest (ROI) focused on two different kidney structures: tubules or glomeruli. Individual glomeruli were identified by a pathologist as either behaving relatively healthy or diseased regardless on if the tissue was DKD or healthy. One glomerulus ROI contains the entirety of a glomerulus. Tubule ROIs were segmented into distal (PanCK+) and proximal (PanCK-) tubule areas of interest (AOI). While both distal and proximal tubules are called tubules, they perform very different functions in the kidney. 

## Loading Data: DCC files, PKC files and annotation file

Download the zipped demo data [at this link](http://nanostring-public-share.s3-website-us-west-2.amazonaws.com/GeoScriptHub/Kidney_Dataset_for_GeomxTools.zip)

Within the zip file you will find the minimal components necessary for analysis. These three data components are DCCs, PKCs, and the annotation file:

* DCCs contain the expression count data
* PKCs contain information about how each probe is associated with a given target gene or portein and any additional panel metadata
* Annotation file specifies useful tissue/ROI/AOI information, including the type of ROI selected, the number of nuclei within an AOI, and other characteristics of the samples.

```{r quickstart, message=FALSE, warning=FALSE}
# Unzip and place the downloaded Kidney Dataset files
# The downloaded dataset contains three folders each containing the respective metadata. 
# We copy the folder path for the downloaded dataset folder titled, 'Kidney_Dataset", as the datadir below and change the 'slash' orientation from 
# "/" instead of "\"

datadir <- file.path("~/DA Vignettes/Kidney_Dataset_for_GeomxTools/Kidney_Dataset/")

DCCFiles <- dir(file.path(datadir, "dccs"), pattern=".dcc$", full.names=TRUE, recursive=TRUE)
PKCFiles <- dir(file.path(datadir, "pkcs"), pattern=".pkc$", full.names=TRUE, recursive=TRUE)
SampleAnnotationFile <- dir(file.path(datadir, "annotation"), pattern=".xlsx$", full.names=TRUE, recursive=TRUE)

demoData <-
  suppressWarnings(readNanoStringGeoMxSet(dccFiles = DCCFiles,
                                          pkcFiles = PKCFiles,
                                          phenoDataFile = SampleAnnotationFile,
                                          phenoDataSheet = "Template",
                                          phenoDataDccColName = "Sample_ID",
                                          protocolDataColNames = c("aoi", "roi"),
                                          experimentDataColNames = c("panel",
                                                                     "instrument_type")))
```

After loading we shift counts with 0 detection to 1 so that during downstream processing and transformations we do not end up with -Inf values in our tables.

``` {r shiftCounts, eval = TRUE}
# Shift counts to one
demoData <- shiftCountsOne(demoData, elt="exprs", useDALogic=TRUE) 
```

## Quality Control Assessment

### Segment QC 

First, we will check sequencing quality and adequate tissue sampling for every segment / AOI. For each segment there are several steps along the way to generating a count matrix, each with it's own quality metric associated and recommended threshold. FASTQ files are generated and converted to DCC files, but before we aggregate DCC files we need to check the sequencing quality within the FASTQ files. We will determine if the samples pass QC based on the number of reads per sample, the percent or reads trimmed and aligned, as well as the sequencing saturation (1 - % unique reads). We will also confirm the number of nuclei & area associated with each segment. At the end of this section we will summarize the breakdown of flags observed, and total number of segments/AOIs that have been flagged for QC failures.

```{r setqcflagupdated,  eval = TRUE}
demoData <- setSegmentQCFlags(demoData, 
                              qcCutoffs = list(minSegmentReads = 1000, # Minimum number of reads
                                               percentAligned = 75,    # Minimum % of reads aligned to known targets
                                               percentSaturation = 50, # Minimum sequencing saturation
                                               minNegativeCount = 5,   # Minimum negative control counts
                                               maxNTCCount = 150,      # Maximum counts observed in NTC well
                                               minNuclei = 15000,      # <- this is swapped?
                                               minArea = 20))          # <- this is swapped?
prData <- protocolData(demoData)
QCResults <- prData[["QCFlags"]]
QCResults <- as.data.frame(QCResults)

# Append relevant variables to the the QC results dataframe. 
QCResults <- cbind(QCResults, sData(demoData)[c( "Raw", "Trimmed", "Trimmed (%)",
                                                 "DeduplicatedReads", "Saturated (%)",
                                                 "Aligned", "Aligned (%)", "Stitched",
                                                 "Stitched (%)", "NTC", "NegGeoMean", 
                                                 "area", "nuclei")])

# Flag sample as PASS or WARNING if sample has a QC flag
QCResults$QCStatus <- apply(prData[["QCFlags"]], 1L, function(x) {
        y <- sum(x) == 0L
        y <- ifelse(y, "PASS", "WARNING")
        return(y)
    })
QCResults <- cbind(QCResults, sData(demoData)[c("aoi", "roi", "slide name")])

# produce QC Table here
flag_columns <- c(colnames(QCResults)[grepl('Low', colnames(QCResults))],
                  colnames(QCResults)[grepl('High', colnames(QCResults))])
QC_Summary <- data.frame(Pass = colSums(!QCResults[, flag_columns]),
                         Warning = colSums(QCResults[, flag_columns]))
QC_Summary['Total Flags', ] <- c(sum(QCResults[, 'QCStatus'] == 'PASS'),
                                sum(QCResults[, 'QCStatus'] == 'WARNING'))
```


```{r QCSummaryTable, echo = FALSE, results = 'asis'}
kable(QC_Summary, format = 'html', 
      caption = 'QC Summary Table for each Segment',
      align = 'c')
```

To view the distribution of these statistics we will generate a few graphs with a quick function to draw histograms of our data using `ggplot2`.

``` {r qcflag histograms, fig.width = 10, fig.height = 8, eval = TRUE, warning = FALSE, message = FALSE}

# Graphical summaries of QC statistics
QC_histogram <- function(assay_data = NULL,
                         annotation = NULL,
                         fill_by = NULL,
                         thr = NULL,
                         xlims = NULL,
                         guides = FALSE) {
  if(is.null(xlims)) {
    xlims <- range(assay_data[, annotation])
  }
  plt <- ggplot(assay_data,
                aes_string(x = paste0('unlist(`', annotation, '`)'),
                           fill = fill_by)) +
    geom_histogram(bins = 50) +
    geom_vline(xintercept = thr, lty = 'dashed', color = 'black') +
    theme_bw() +
    facet_wrap(as.formula(paste('~', fill_by)), nrow = 8) +
    xlim(xlims) +
    labs(x = annotation, y = 'AOIs, #', title = annotation)
  if(!guides) {
    plt <- plt + guides(fill = 'none')
  }
  plt
}

## Troubleshoot error:
##   Warning message:
##   Removed 8 rows containing missing values (geom_bar).
plts <- list()
plts[[1]] <- QC_histogram(sData(demoData), 'Aligned (%)', 'region', 80, c(0,100))
plts[[2]] <- QC_histogram(sData(demoData), 'Stitched (%)', 'region', 80, c(0,100))
plts[[3]] <- QC_histogram(sData(demoData), 'Trimmed (%)', 'region', 80, c(0,100))
plts[[4]] <- QC_histogram(sData(demoData), 'Saturated (%)', 'region', 80, c(0,100))
plts[[5]] <- QC_histogram(sData(demoData), 'NegGeoMean', 'region', 5)
plts[[6]] <- QC_histogram(sData(demoData), 'area', 'region', 15000)
plts[[7]] <- QC_histogram(sData(demoData), 'nuclei', 'region', 20)

plot_grid(plotlist = plts[1:7], nrow = 2, ncol = 4)

```

###  Exclude samples that did not pass Sequencing QC

```{r remove QCSampleProbe, eval = TRUE}
QCResultsIndex <- which(apply(protocolData(demoData)[["QCFlags"]], 
                              1L , function(x) sum(x) == 0L))
QCPassed <- demoData[, QCResultsIndex]

# QC Passed is your pruned dataset without the Sequencing QC warning AOIs
# Setting demoData to contain only those that passed AOI QC
demoData <- QCPassed
dim(demoData) 

```

### Biological Probe QC 

In some GeoMx assays we rely on multiple probes per target to represent expression of a given gene. Across all NGS read-out assays, there are multiple probes representing our negative controls, which should not bind to any sequence in the genome. Before we summarize our data into a count matrix, we will remove probes for which we observe expression that appears spurious. This process is called outlier removal, which is performed on either a per gene (global) or per gene per AOI (local) basis. This process is only performed for targets where there are multiple ISH probes related to that target, so for our example data it will only be performed on the negative control probes. This process will always leave at least one probe representing the gene or biological target class in the dataset after the process.

#### Set Biological Probe QC flags using default settings

[text describing defaults & rationale]

```{r setbioprobeqcflag,  eval = TRUE}
# Generally keep the qcCutoffs parameters unchanged. Set removeLocalOutliers to 
# FALSE if you do not want to remove local outliers
demoData <- setBioProbeQCFlags(demoData, 
                               qcCutoffs=list(minProbeRatio=0.1,
                                              percentFailGrubbs=20), 
                               removeLocalOutliers=TRUE)

ProbeQCResults <- fData(demoData)[["QCFlags"]]

# Define QC table for Probe QC
qc_df <- data.frame(Passed = sum(rowSums(ProbeQCResults[, -1]) == 0),
                    Global = sum(ProbeQCResults$GlobalGrubbsOutlier),
                    Local = sum(rowSums(ProbeQCResults[, -2:-1])>0))
```

```{r bioprobeQCTable, echo = FALSE, results = 'asis'}
kable(qc_df, caption = 'Probes flagged or passed as outliers')

```

```{r excludeOutlierProbes}  
#Subset object to exclude all that did not pass Global Bioprobe QC and Outlier Ratio QC
ProbeQCPassed <- subset(demoData, 
                     fData(demoData)[["QCFlags"]][,c("LowProbeRatio")]== FALSE &
                       fData(demoData)[["QCFlags"]][,c("GlobalGrubbsOutlier")]== FALSE)
dim(ProbeQCPassed)
demoData <- ProbeQCPassed 
```

### Calculate Limit of Quantification

In addition to outlier detection, we must now determine the limit of quantification. This is calculated based on the distribution of negative control probes, and is intended to represent the quantifiable limit of gene expression per segment, under which gene expression is no longer reliable. Please note that this process is more stable in larger segments, and AOIs with low area, and subsequently low negative control probe distributions, the LOQ may not be accurately reflective of true signal detection rates. The formula for calculating the LOQ in the _i_^th^ segment/AOI is: $$LOQ_{i} = geomean(NegProbe_{i}) * geoSD(NegProbe_{i})^{n}$$

In the example below we use 2 geometric standard deviations (n = 2) above the geometric mean as the cutoff, which is recommended for most use cases. We also recommend that a minimum LOQ of 2 be used even if the LOQ calculated to be below this threshold.

``` {r calculateLOQ, eval = TRUE}
# Create a function to define and calculate the LOQ:
calc_LOQ <- function(object = NULL,
                     cutoff = 2,
                     minLOQ = 2) {
  negativeObject <- negativeControlSubset(object)
  esApply(negativeObject, MARGIN=2, FUN=function(x) {
    pmax(ngeoMean(x) * ngeoSD(x) ^ cutoff, minLOQ)})
}

pData(demoData)$LOQ <- calc_LOQ(demoData)

```

#### Create Gene-level Count Data

After calculating the LOQ we will generate a target count matrix. This will summarize all multi-probe targets into a single value represented as the geometric mean of those probes.

```{r aggregateCounts, eval = TRUE}
# Check how many unique targets the object has
length(unique(featureData(demoData)[["TargetName"]]))

# collapse to targets
target_demoData <- aggregateCounts(demoData)
dim(target_demoData)
exprs(target_demoData)[1:5, 1:2]

```

### Segment/AOI Filtering

We recommend removing poor performing AOIs before further analysis as they may unduly influence interpretation downstream. Please note that if there are rare segment classes that are only represented by a few AOIs, that you may want to skip this section, but that interpretation of these segments should primarily be qualitative, not quantitative to prevent biased interpretation of the data.

{Include section on Segment filtering - Q90 distribution?}

// need input from team here on what to show or if we should skip this section

### Gene Filtering 

After filtering segments with poor detection, we recommend removing genes which were poorly detected. This helps improve performance during downstream statistical tests, decreases multiple testing penalties, and may prevent interpreting stochastic expression of genes near the LOQ as biological signal.

First we will determine the number of genes detected at various cutoffs across our dataset. For each gene will will determine how many segments have expression > LOQ, and plot this information to help select a cut-point for minimal detection. We will also show you how to examine the detection rates of genes of interest, saved here as a list of gene symbols.

```{r geneDetectionRate, eval = TRUE}
pData(target_demoData)$LOQ <- pData(demoData)$LOQ
loq_test <- function(x) {x > LOQ}
LOQ_Mat <- t(esApply(target_demoData, MARGIN=1, FUN=loq_test))

# Save detection rate information to pheno & feature data
pData(target_demoData)$GenesDetected <- colSums(LOQ_Mat, na.rm = TRUE)
fData(target_demoData)$DetectedSegments <- rowSums(LOQ_Mat, na.rm = TRUE)
fData(target_demoData)$DetectionRate <- fData(target_demoData)$DetectedSegments / nrow(pData(target_demoData))

# Gene of interest detection table
goi <- c('PDCD1','CD274','IFNG','CD8A','CD68','EPCAM','KRT18','NPHS1','NPHS2','CALB1','CLDN8')
goi_df <- data.frame(Gene = goi,
                     Detection = fData(target_demoData)[goi, 'DetectedSegments'],
                     Rate = round(fData(target_demoData)[goi, 'DetectionRate'] * 100, 1))
```

```{r tableGOI, echo = FALSE, results = 'asis'}
kable(goi_df, caption = 'Detection rate for Genes of Interest', align = 'c')
```

```{r plotDetectionRate, eval = TRUE}
# Plot detection rate:
plot_detect <- data.frame(Freq = c(1, 5, 10, 20, 30, 50))
plot_detect$Number <-
  unlist(lapply(c(0.01, 0.05, 0.1, 0.2, 0.3, 0.5),
                function(x) {sum(fData(target_demoData)$DetectionRate >= x)}))
plot_detect$Rate <- plot_detect$Number / nrow(fData(target_demoData))
rownames(plot_detect) <- plot_detect$Freq

ggplot(plot_detect, aes(x = as.factor(Freq), y = Rate, fill = Rate)) +
    geom_bar(stat = 'identity') +
    geom_text(aes(label = formatC(Number, format = 'd', big.mark = ',')),
              vjust=1.6, color = 'black', size = 4) +
    scale_fill_gradient2(low = 'orange2', mid = 'lightblue',
                         high = 'dodgerblue3', midpoint = 0.65,
                         limits = c(0,1),
                         labels = scales::percent) +
    theme_bw() +
    scale_y_continuous(labels = scales::percent, limits = c(0,1),
                       expand = expansion(mult = c(0, 0))) +
    labs(x = '% of Segments',
         y = 'Genes Detected, % of Panel > LOQ')
```

As we have confirmed that most of the target genes of interest are detected at > 10% of AOIs, we will out genes detected in < 10% of segments. If a target gene was detected in < 10% of AOIs, it could be manually saved or a lower threshold could be selected.

``` {r subsetGenes, eval = TRUE}
# Subset to target genes detected in at least 10% of the samples.
#   Also manually include the negative control probe, for downstream use
neg_probe <- rownames(exprs(target_demoData))[grepl('Neg', rownames(target_demoData@assayData$exprs))]
target_demoData <- target_demoData[fData(target_demoData)$DetectionRate > 0.1 |
                                     fData(target_demoData)$TargetName == neg_probe, ]
goi <- goi[goi %in% results$Gene] # remove genes we filtered out above for later use
```

## Normalization

We will now normalize the GeoMx data for downstream visualizations and differential expression. Two common methods for normalization are i) Quartile 3 or ii) background normalization.

Both of these normalization methods rely on the distribution of the data to estimate a normalization factor to roughly bring the data distributions together. More advanced methods for normalization and modelings are under active development, however, for most projects these methods are sufficient for understanding differences between biological classes of segments and samples. Additionally other packages such as `limma` and `voom` may also be appropriate in some cases.

Before we choose a normalization factor to use, we will explore the relationship between the upper quartile (Q3) of the counts in each segment with the geometric mean of the negative control probes in the data. We'd ideally like there to be separation between these two values before normalizing to one of them. If you do not see sufficient seperation between these values, you may need to be more aggressive with filtering out low-expressing genes.

For additional guidance, please refer to our [Data Analysis & Normalization White Paper for DSP-NGS Assays](whitepaper url)

``` {r, previewNF, fig.width = 8, fig.height = 6.5, eval = TRUE}
# Graph Q3 value vs negGeoMean of Negatives
ann_of_interest <- 'region'
Stat_data <- data.frame(row.names = colnames(exprs(target_demoData)),
                        AOI = colnames(exprs(target_demoData)),
                        Annotation = pData(target_demoData)[, ann_of_interest],
                        Q3 = unlist(apply(exprs(target_demoData), 2, quantile, 0.75, na.rm = TRUE)),
                        NegProbe = exprs(target_demoData)[neg_probe, ])
Stat_data_m <- melt(Stat_data, measure.vars = c('Q3','NegProbe'),
                    variable.name = 'Statistic', value.name = 'Value')

plts <- list()
plt1 <- ggplot(Stat_data, aes(x = NegProbe, y = Q3, color = Annotation)) +
  geom_abline(intercept = 0, slope = 1, lty = 'dashed', color = 'darkgray') +
  geom_point() + guides(color = 'none') + theme_bw() +
  scale_x_continuous(trans = 'log2') + scale_y_continuous(trans = 'log2') +
  theme(aspect.ratio = 1) +
  labs(x = 'Negative Probe GeoMean, Counts', y = 'Q3 Value, Counts')

plt2 <- ggplot(Stat_data, aes(x = NegProbe, y = Q3/NegProbe, color = Annotation)) +
  geom_hline(yintercept = 1, lty = 'dashed', color = 'darkgray') +
  geom_point() + guides(color = 'none') + theme_bw() +
  scale_x_continuous(trans = 'log2') + scale_y_continuous(trans = 'log2') +
  theme(aspect.ratio = 1) +
  labs(x = 'Negative Probe GeoMean, Counts', y = 'Q3/NegProbe Value, Counts')

plt3 <- ggplot(Stat_data_m, aes(x = Value, fill = Statistic)) +
  geom_histogram(bins = 40) + theme_bw() + scale_x_continuous(trans = 'log2') +
  facet_wrap(~Annotation, nrow = 5) +
  labs(x = 'Counts', y = 'AOIs, #')

top_row <- plot_grid(plt1, plt2, nrow = 1, labels = c('A','B'))
plot_grid(top_row, plt3, ncol = 1, labels = c('','C'))
```

[TEXT HERE]

```{r normalizeObject, opt.width = .5, eval = TRUE}
# Q3 norm (75th percentile) for WTA/CTA  with or without custom spike-ins
target_demoData <- normalize(target_demoData , data_type = "RNA", norm_method = "quant", 
                             desiredQuantile = .75, toElt = "q_norm")
# Background normalization for WTA/CTA without custom spike-in
target_demoData <- normalize(target_demoData , data_type = "RNA", norm_method = "neg", 
                             fromElt = "exprs",  toElt = "neg_norm")
# visualize the first 10 segments with each normalization method
```

```{r normplot, out.width=c('33%', '33%', '33%'), fig.show='hold'}
boxplot(exprs(target_demoData)[,1:10], col = '#9EDAE5', main = 'Raw Counts',
        log = 'y', names = 1:10, xlab = 'Segment', ylab = 'Counts, Raw')
boxplot(assayDataElement(target_demoData[,1:10], elt = 'q_norm'), col = '#2CA02C', main = 'Q3 Norm Counts',
        log = 'y', names = 1:10, xlab = 'Segment', ylab = 'Counts, Q3 Normalized')
boxplot(assayDataElement(target_demoData[,1:10], elt = 'neg_norm'), col = '#FF7F0E', main = 'Neg Norm Counts',
        log = 'y', names = 1:10, xlab = 'Segment', ylab = 'Counts, Neg. Normalized')

```

## Downstream Analysis

### Dimension Reduction: UMAP & t-SNE

One common approach to understanding the data after normalization is to plot the data in a reduced dimensionality space. Two common methods for this are UMAP and tSNE projections, which are non-orthogonally constrained projections which can cluster samples based on overall gene expression rates. In this example we see that by either UMAP (from the `umap` package) or tSNE (from the `Rtsne` package) we see 3 distinct clusters of samples: tubules, healthy (normal) glomeruli, and abnormal (disease-like) glomeruli.

``` {r dimReduction, eval = TRUE, out.width=c('50%', '50%'), fig.show='hold'}
# update defaults for umap to contain a stable random_state (seed)
custom_umap <- umap.defaults
custom_umap$random_state <- 42

# run UMAP
umap_out <- umap(t(na.omit(log2(assayDataElement(target_demoData , elt = "q_norm")))),  
                 config = custom_umap)
pData(target_demoData)$UMAP1 <- umap_out$layout[,1]
pData(target_demoData)$UMAP2 <- umap_out$layout[,2]

ggplot(pData(target_demoData),
       aes(x = UMAP1, y = UMAP2, color = region, shape = pathology)) +
  geom_point(size = 3) +
  theme_bw()

# run tSNE
tsne_out <- Rtsne(t(na.omit(log2(assayDataElement(target_demoData , elt = "q_norm")))), perplexity = 5)
pData(target_demoData)$tSNE1 <- tsne_out$Y[,1]
pData(target_demoData)$tSNE2 <- tsne_out$Y[,2]

ggplot(pData(target_demoData),
       aes(x = tSNE1, y = tSNE2, color = region, shape = pathology)) +
  geom_point(size = 3) +
  theme_bw()
```

### Differential Expression

A common method for understanding distinctions between groups of segments or patients is to perform differential expression analysis. While more advanced methods for modeling the underlying count distribution are being actively developed, a common approach to performing differential expression testing is to use a mixed-effect regression. These regressions use additional information to control for batch-specific effects which may confound the results otherwise. For GeoMx, we use random slopes or intercepts to control for slide-specific effects, setting our fixed effect to the variable we want to model explicitly. Below we use the package `lme4` to model the data and `lmerTest` to estimate the significance of interactions. For more information about mixed effect models please see [the original lme4 documentation](link to LME4).

Because we aren't explicitly factoring our test, or fixed effect, variable, the code will have run factor on the test variable (region). By default this will end up putting which means negative values of the Estimate (log~2~ FC) will be enriched in glomeruli, and postive values will be enriched in tubules. To control the order and interpretation of an lmm it may be worthwhile to create a new annotation column that is a factor not a string by calling:<\br>
`pData(target_demoDate)$Test <- factor(pData(target_demoData), levels = c('glomerulus','tubule')`

``` {r DE, eval = TRUE, warning = FALSE, message = FALSE}
# Analysis example:
# Glomeruli vs Tubules - mixed slope + intercept because the test is performed
#     comparing paired ROIs within a slide 
# NOTE: if using a comparison between exclusively between different slides:
#    e.g. disease status, only a random intercept is recommended such that the formula
#    would be lmer(log2(y) ~ disease + (1|`slide name`)) instead

lmm <- function(y) {
  coef(summary(lmer(log2(y) ~ region + (1 + `slide name`| `slide name`))))[2, c(1,5)]
}
results <- t(suppressMessages(assayDataApply(target_demoData,
                                             elt = "q_norm", MARGIN = 1, lmm)))

# DE results are just stored as a table here, but could also be stored in fData
results <- cbind(data.frame(Gene = rownames(results)),
                 as.data.frame(results))
results$FDR <- p.adjust(results$`Pr(>|t|)`, method = 'fdr')

## below is work-around text to quick load DE results from a saved csv for convenience:
# results <- read.csv('~/DE_results_for_testing.csv')
# colnames(results) <- c('Gene','Estimate','Pr(>|t|)','FDR')
# rownames(results) <- results$Gene
```

Let's take a look at our genes of interest and what their log~2~ fold change (`Estimate`), P-value (`Pr(>|t|)`), and FDR are. We can do this by simply subsetting the results table we just generated by typing `results[goi, ]`. 

``` {r DEtable, echo = FALSE, results = 'asis', }
kable(results[goi[goi %in% rownames(results)], ], digits = 3,  caption = 'DE results for Genes of Interest', align = 'lc')
```

Now let's code a simple `ggplot2` graph for a volcano plot, which will color based on various cuts in the significance threshold and label genes with a P-value of < 1e-15. 

``` {r volcanoPlot, fig.width = 10, fig.height = 8}
# Categorize Results based on P-value & FDR for plotting
results$Color <- 'NS or FC < 0.5'
results$Color[results$P < 0.05] <- 'P < 0.05'
results$Color[results$FDR < 0.05] <- 'FDR < 0.05'
results$Color[results$FDR < 0.001] <- 'FDR < 0.001'
results$Color[abs(results$Estimate) < 0.5] <- 'NS or FC < 0.5'
results$Color <- factor(results$Color, levels = c('NS or FC < 0.5', 'P < 0.05', 'FDR < 0.05', 'FDR < 0.001'))

# Graph results
plt <- ggplot(results,
              aes(x = Estimate, y = -log10(`Pr(>|t|)`),
                  color = Color, label = Gene)) +
  geom_vline(xintercept = c(0.5, -0.5), lty = 'dashed') +
  geom_hline(yintercept = -log10(0.05), lty = 'dashed') +
  geom_point() +
  labs(x = 'Enriched in Glomeruli <- log2(FC) -> Enriched in Tubules',
       y = 'Significance, -log10(P)',
       color = 'Significance') +
  scale_color_manual(values = c(`FDR < 0.001` = 'dodgerblue',
                                `FDR < 0.05` = 'lightblue',
                                `P < 0.05` = 'orange2',
                                `NS or FC < 0.5` = 'gray')) +
  scale_y_continuous(expand = expansion(mult = c(0,0.05))) +
  geom_text_repel(data = subset(results, `Pr(>|t|)` < 1e-15),
                  size = 3.5, point.padding = 0.15, color = 'black',
                  min.segment.length = .1, box.padding = .2, lwd = 2) +
  theme_bw()

print(plt)
```

### Visualizing differentially expressed genes

[TEXT HERE]

``` {r targetExprs, eval = TRUE, out.width=c('50%', '50%'), fig.show='hold'}
# show expression for a single target: NPHS2
ggplot(pData(target_demoData),
       aes(x = region, fill = region,
           y = assayDataElement(target_demoData['NPHS2', ], elt = 'q_norm'))) +
  geom_boxplot() +
  labs(y = 'NPHS2') +
  scale_y_continuous(trans = 'log2') +
  theme_bw()

# show expression of NPHS2 vs CD24
glom <- pData(target_demoData)$region == 'glomerulus'
ggplot(pData(target_demoData),
       aes(x = assayDataElement(target_demoData['CD24', ], elt = 'q_norm'),
           y = assayDataElement(target_demoData['NPHS2', ], elt = 'q_norm'),
           color = region, shape = pathology)) +
  geom_vline(xintercept = max(assayDataElement(target_demoData['CD24', glom], elt = 'q_norm')),
             lty = 'dashed', col = 'darkgray') +
  geom_hline(yintercept = max(assayDataElement(target_demoData['NPHS2', !glom], elt = 'q_norm')),
             lty = 'dashed', col = 'darkgray') +
  geom_point(size = 3) +
  theme_bw() +
  scale_x_continuous(trans = 'log2') + scale_y_continuous(trans = 'log2') +
  labs(x = 'CD24, Q3 Counts', y = 'NPHS2, Q3 Counts')

```

[TEXT HERE]

``` {r heatmap, eval = TRUE, fig.width = 8, fig.height = 6.5}
# select top significant genes based on significance, plot with pheatmap
GOI <- subset(results, `Pr(>|t|)` < 1e-10)$Gene
pheatmap(log2(assayDataElement(target_demoData[GOI, ], elt = 'q_norm')),
         scale = 'row', 
         show_rownames = FALSE, show_colnames = FALSE,
         border_color = NA,
         breaks = seq(-3, 3, 0.05),
         color = colorRampPalette(c('purple3','black','yellow2'))(120),
         annotation_col = pData(target_demoData)[, c('region','class')])
```

``` {r autoheatmap, eval = TRUE, fig.width = 8, fig.height = 6.5}
# The GeomxTools package also includes heatmap functionality in the graph
# autoplot as a simple additional method for graphing your data
autoplot(target_demoData[GOI, ], type = 'heatmap-genes',
         elt = 'q_norm', heatmapGroup = c('region','class'))
```